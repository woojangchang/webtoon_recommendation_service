{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ce0e72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요 라이브러리 호출\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from konlpy.tag import Okt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "202e3f42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "      <th>score_num</th>\n",
       "      <th>best_num</th>\n",
       "      <th>best</th>\n",
       "      <th>best_recomm</th>\n",
       "      <th>best_unrecomm</th>\n",
       "      <th>comment_num</th>\n",
       "      <th>comment</th>\n",
       "      <th>star</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>웰캄투실버라이프</td>\n",
       "      <td>9.94</td>\n",
       "      <td>19878</td>\n",
       "      <td>15</td>\n",
       "      <td>아 할머니 귀여우시다 힐링툰 감이 오네요 잘볼게용!\\n시리얼에 뜨거운 우유...나만...</td>\n",
       "      <td>52588</td>\n",
       "      <td>599</td>\n",
       "      <td>2220</td>\n",
       "      <td>정주행 시작\\n솔찍히 자는데 깨우면 짜증남..할머니라도..맘은 이해하지만 더 자고 ...</td>\n",
       "      <td>9.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>원수를 사랑하라</td>\n",
       "      <td>9.95</td>\n",
       "      <td>31528</td>\n",
       "      <td>15</td>\n",
       "      <td>근데 여주 대단하다...엄마랑 아빠가 저런 사람들인데 멀끔히 차려입고 면접보는 거면...</td>\n",
       "      <td>129562</td>\n",
       "      <td>3792</td>\n",
       "      <td>987</td>\n",
       "      <td>근데 나 자신을 믿는것.. 지금 내가 제일 필요한 말임..ㅠㅠㅠㅠㅠ 어제 면접 말려...</td>\n",
       "      <td>9.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>약초마을 연쇄살초사건</td>\n",
       "      <td>9.73</td>\n",
       "      <td>10367</td>\n",
       "      <td>15</td>\n",
       "      <td>아니ㅋㅋㅋㅋㅋㅋ작가님ㅋㅋㅋㅋㅋㅋ이제 작물 쪽으로 길을 트신건가요ㅋㅋㅋㅋㅋㅋㅋㅋ\\n팀...</td>\n",
       "      <td>63294</td>\n",
       "      <td>255</td>\n",
       "      <td>1462</td>\n",
       "      <td>이거 왤케 재밌냨ㅋ 팀장님 죽었는데 뒷담 까는거 보소\\n약초마을 연쇄살인도 아닌 연...</td>\n",
       "      <td>9.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AI가 세상을 지배한다면</td>\n",
       "      <td>9.88</td>\n",
       "      <td>12207</td>\n",
       "      <td>15</td>\n",
       "      <td>그대가 POGO 싶었소\\n라움 코드 자기가 넣었다고... 이리 당당하게 선전POGO...</td>\n",
       "      <td>59238</td>\n",
       "      <td>967</td>\n",
       "      <td>2036</td>\n",
       "      <td>완결보고 정주행만 3번째 볼때마다 감정이 다름 영화로 나오기엔 잘라내거나 스토리에 ...</td>\n",
       "      <td>9.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>닥터 프로스트 시즌 3~4</td>\n",
       "      <td>9.95</td>\n",
       "      <td>30579</td>\n",
       "      <td>15</td>\n",
       "      <td>아무생각없이 내렸다가 이거 보고 놀란사람 손!!!\\n헐?\\n제가 이 웹툰을 보면서 ...</td>\n",
       "      <td>119758</td>\n",
       "      <td>2817</td>\n",
       "      <td>9707</td>\n",
       "      <td>퍄ㅑㅑ\\n닥프 1기 2기 무료로 풀려있으니까 꼭보세요\\n아 이런 띵작은 유료되기전에...</td>\n",
       "      <td>9.97</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            title  score  score_num  best_num  \\\n",
       "0        웰캄투실버라이프   9.94      19878        15   \n",
       "1        원수를 사랑하라   9.95      31528        15   \n",
       "2     약초마을 연쇄살초사건   9.73      10367        15   \n",
       "3   AI가 세상을 지배한다면   9.88      12207        15   \n",
       "4  닥터 프로스트 시즌 3~4   9.95      30579        15   \n",
       "\n",
       "                                                best  best_recomm  \\\n",
       "0  아 할머니 귀여우시다 힐링툰 감이 오네요 잘볼게용!\\n시리얼에 뜨거운 우유...나만...        52588   \n",
       "1  근데 여주 대단하다...엄마랑 아빠가 저런 사람들인데 멀끔히 차려입고 면접보는 거면...       129562   \n",
       "2  아니ㅋㅋㅋㅋㅋㅋ작가님ㅋㅋㅋㅋㅋㅋ이제 작물 쪽으로 길을 트신건가요ㅋㅋㅋㅋㅋㅋㅋㅋ\\n팀...        63294   \n",
       "3  그대가 POGO 싶었소\\n라움 코드 자기가 넣었다고... 이리 당당하게 선전POGO...        59238   \n",
       "4  아무생각없이 내렸다가 이거 보고 놀란사람 손!!!\\n헐?\\n제가 이 웹툰을 보면서 ...       119758   \n",
       "\n",
       "   best_unrecomm  comment_num  \\\n",
       "0            599         2220   \n",
       "1           3792          987   \n",
       "2            255         1462   \n",
       "3            967         2036   \n",
       "4           2817         9707   \n",
       "\n",
       "                                             comment  star  \n",
       "0  정주행 시작\\n솔찍히 자는데 깨우면 짜증남..할머니라도..맘은 이해하지만 더 자고 ...  9.98  \n",
       "1  근데 나 자신을 믿는것.. 지금 내가 제일 필요한 말임..ㅠㅠㅠㅠㅠ 어제 면접 말려...  9.92  \n",
       "2  이거 왤케 재밌냨ㅋ 팀장님 죽었는데 뒷담 까는거 보소\\n약초마을 연쇄살인도 아닌 연...  9.87  \n",
       "3  완결보고 정주행만 3번째 볼때마다 감정이 다름 영화로 나오기엔 잘라내거나 스토리에 ...  9.94  \n",
       "4  퍄ㅑㅑ\\n닥프 1기 2기 무료로 풀려있으니까 꼭보세요\\n아 이런 띵작은 유료되기전에...  9.97  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 불러오기\n",
    "df = pd.read_csv('data/naver_comment_2.csv', encoding='utf-8-sig')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd11a8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "okt = Okt()\n",
    "def okt_tokenizer(text):\n",
    "    tokens_ko = okt.morphs(text, stem=True)\n",
    "    return tokens_ko\n",
    "\n",
    "import re\n",
    "\n",
    "def hangul(text):\n",
    "    return re.sub(\"[^가-힣ㄱ-하-ㅣ\\\\s]\", \"\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e694f1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Embedding\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "def train_to_evaluate(X, y, file_name, max_words=10000, maxlen=30, embedding_dim=100, *args):\n",
    "    \n",
    "    tokenizer = Tokenizer(num_words=max_words)\n",
    "    tokenizer.fit_on_texts(X)\n",
    "    X_seq = tokenizer.texts_to_sequences(X)\n",
    "\n",
    "    X_pad = pad_sequences(X_seq, maxlen=maxlen)\n",
    "    y = np.asarray(y)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_pad, y, test_size=0.2, random_state=0)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Embedding(max_words, embedding_dim, input_length=maxlen))\n",
    "    model.add(Flatten())\n",
    "    for unit in args:\n",
    "        model.add(Dense(unit, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    cp = ModelCheckpoint(filepath='data/'+file_name,\n",
    "                         monitor='accuracy',\n",
    "                         save_best_only=True)\n",
    "    \n",
    "    es = EarlyStopping(monitor='accuracy',\n",
    "                       patience=15)\n",
    "    \n",
    "    \n",
    "    hist = model.fit(X_train, y_train,\n",
    "                     epochs=100, batch_size=32,\n",
    "                     validation_data=(X_val, y_val),\n",
    "                     callbacks=[cp, es],\n",
    "                     verbose=0)\n",
    "    \n",
    "    \n",
    "    model.load_weights('data/'+file_name)\n",
    "    loss, accuracy = model.evaluate(X_val, y_val, verbose=0)\n",
    "#     print('MAE :', np.round(mae, 4), 'RMSE :', np.round(np.sqrt(mse), 4))\n",
    "        \n",
    "    return model, hist, loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed1c013b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9.9 이상, 미만 비율이 6:4\n",
    "def category(star):\n",
    "    if star >= 9.9:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ee3e4c",
   "metadata": {},
   "source": [
    "# 베댓만"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0244977f",
   "metadata": {},
   "source": [
    "## 1. Dense 층 없이"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad6018ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = df['best']\n",
    "y = df['star'].apply(category)\n",
    "\n",
    "X1 = X1.apply(okt_tokenizer).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ded07108",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 10/10 [38:53<00:00, 233.35s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "bestmodel = None\n",
    "bestacc = 0\n",
    "bestmxwords = None\n",
    "bestmxlen = None\n",
    "bestembdim = None\n",
    "bestunit = None\n",
    "result_df = pd.DataFrame(columns=['maxwords', 'maxlen', 'embedding_dim', 'loss', 'accuracy'])\n",
    "\n",
    "for mxwords in tqdm(range(10, 100+1, 10)):\n",
    "    for mxlen in [20, 25, 30]:\n",
    "        for embdim in range(10, 100+1, 5):\n",
    "            model = train_to_evaluate(X1, y, 'embedding1_category.h5', mxwords, mxlen, embdim)\n",
    "            result_df.loc[len(result_df)] = [mxwords, mxlen, embdim, model[2], model[3]]\n",
    "            if bestacc < model[3]:\n",
    "                bestmodel = model\n",
    "                bestacc = model[3]\n",
    "                bestmxwords = mxwords\n",
    "                bestmxlen = mxlen\n",
    "                bestembdim = embdim\n",
    "                \n",
    "bestmodel[0].save('data/embedding1_category.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48f5c597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6518, loss: 0.7934\n",
      "--bestmxwords: 40, --bestmxlen: 25, --bestembdim: 10\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy: {bestmodel[3]:.4f}, loss: {bestmodel[2]:.4f}')\n",
    "print(f'--bestmxwords: {bestmxwords}, --bestmxlen: {bestmxlen}, --bestembdim: {bestembdim}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58d6816d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>maxwords</th>\n",
       "      <th>maxlen</th>\n",
       "      <th>embedding_dim</th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.756928</td>\n",
       "      <td>0.526786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.777922</td>\n",
       "      <td>0.580357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>100.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.784888</td>\n",
       "      <td>0.526786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>70.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.788699</td>\n",
       "      <td>0.580357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>40.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.793409</td>\n",
       "      <td>0.651786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>10.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.796037</td>\n",
       "      <td>0.562500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.796811</td>\n",
       "      <td>0.562500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>90.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.804651</td>\n",
       "      <td>0.535714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>100.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.807502</td>\n",
       "      <td>0.544643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>90.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>0.809602</td>\n",
       "      <td>0.526786</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     maxwords  maxlen  embedding_dim      loss  accuracy\n",
       "16       10.0    20.0           90.0  0.756928  0.526786\n",
       "0        10.0    20.0           10.0  0.777922  0.580357\n",
       "561     100.0    30.0           60.0  0.784888  0.526786\n",
       "386      70.0    30.0           40.0  0.788699  0.580357\n",
       "190      40.0    25.0           10.0  0.793409  0.651786\n",
       "31       10.0    25.0           70.0  0.796037  0.562500\n",
       "1        10.0    20.0           15.0  0.796811  0.562500\n",
       "480      90.0    25.0           35.0  0.804651  0.535714\n",
       "565     100.0    30.0           80.0  0.807502  0.544643\n",
       "492      90.0    25.0           95.0  0.809602  0.526786"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.sort_values(by=['loss']).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe999362",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>maxwords</th>\n",
       "      <th>maxlen</th>\n",
       "      <th>embedding_dim</th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>40.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.793409</td>\n",
       "      <td>0.651786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>40.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.899858</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>40.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.883529</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>40.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.887582</td>\n",
       "      <td>0.633929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>40.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.870686</td>\n",
       "      <td>0.633929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>30.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.134634</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>40.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.856500</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>40.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.848120</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>40.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.910253</td>\n",
       "      <td>0.616071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>40.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.849257</td>\n",
       "      <td>0.616071</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     maxwords  maxlen  embedding_dim      loss  accuracy\n",
       "190      40.0    25.0           10.0  0.793409  0.651786\n",
       "173      40.0    20.0           20.0  0.899858  0.642857\n",
       "186      40.0    20.0           85.0  0.883529  0.642857\n",
       "193      40.0    25.0           25.0  0.887582  0.633929\n",
       "187      40.0    20.0           90.0  0.870686  0.633929\n",
       "135      30.0    25.0           20.0  1.134634  0.625000\n",
       "181      40.0    20.0           60.0  0.856500  0.625000\n",
       "180      40.0    20.0           55.0  0.848120  0.625000\n",
       "174      40.0    20.0           25.0  0.910253  0.616071\n",
       "185      40.0    20.0           80.0  0.849257  0.616071"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.sort_values(by=['accuracy'], ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b423bc17",
   "metadata": {},
   "source": [
    "## 특문 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8eee914",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1a = df['best'].apply(hangul)\n",
    "X1a = X1a.apply(okt_tokenizer).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e35a7d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 10/10 [39:37<00:00, 237.76s/it]\n"
     ]
    }
   ],
   "source": [
    "bestmodel = None\n",
    "bestacc = 0\n",
    "bestmxwords = None\n",
    "bestmxlen = None\n",
    "bestembdim = None\n",
    "bestunit = None\n",
    "result_df = pd.DataFrame(columns=['maxwords', 'maxlen', 'embedding_dim', 'loss', 'accuracy'])\n",
    "\n",
    "for mxwords in tqdm(range(10, 100+1, 10)):\n",
    "    for mxlen in [20, 25, 30]:\n",
    "        for embdim in range(10, 100+1, 5):\n",
    "            model = train_to_evaluate(X1a, y, 'embedding1a_category.h5', mxwords, mxlen, embdim)\n",
    "            result_df.loc[len(result_df)] = [mxwords, mxlen, embdim, model[2], model[3]]\n",
    "            if bestacc < model[3]:\n",
    "                bestmodel = model\n",
    "                bestacc = model[3]\n",
    "                bestmxwords = mxwords\n",
    "                bestmxlen = mxlen\n",
    "                bestembdim = embdim\n",
    "                \n",
    "bestmodel[0].save('data/embedding1a_category.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "57f8a09b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6786, loss: 0.7849\n",
      "--bestmxwords: 60, --bestmxlen: 30, --bestembdim: 80\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy: {bestmodel[3]:.4f}, loss: {bestmodel[2]:.4f}')\n",
    "print(f'--bestmxwords: {bestmxwords}, --bestmxlen: {bestmxlen}, --bestembdim: {bestembdim}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dd79be0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>maxwords</th>\n",
       "      <th>maxlen</th>\n",
       "      <th>embedding_dim</th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>100.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.715474</td>\n",
       "      <td>0.616071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.722290</td>\n",
       "      <td>0.526786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.737564</td>\n",
       "      <td>0.535714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>100.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>0.745339</td>\n",
       "      <td>0.589286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.745827</td>\n",
       "      <td>0.517857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.750044</td>\n",
       "      <td>0.526786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569</th>\n",
       "      <td>100.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.751053</td>\n",
       "      <td>0.598214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.753073</td>\n",
       "      <td>0.526786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>100.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.753302</td>\n",
       "      <td>0.607143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>100.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.757537</td>\n",
       "      <td>0.553571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     maxwords  maxlen  embedding_dim      loss  accuracy\n",
       "554     100.0    30.0           25.0  0.715474  0.616071\n",
       "6        10.0    20.0           40.0  0.722290  0.526786\n",
       "12       10.0    20.0           70.0  0.737564  0.535714\n",
       "568     100.0    30.0           95.0  0.745339  0.589286\n",
       "5        10.0    20.0           35.0  0.745827  0.517857\n",
       "0        10.0    20.0           10.0  0.750044  0.526786\n",
       "569     100.0    30.0          100.0  0.751053  0.598214\n",
       "1        10.0    20.0           15.0  0.753073  0.526786\n",
       "561     100.0    30.0           60.0  0.753302  0.607143\n",
       "566     100.0    30.0           85.0  0.757537  0.553571"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.sort_values(by=['loss']).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d52648e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>maxwords</th>\n",
       "      <th>maxlen</th>\n",
       "      <th>embedding_dim</th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>60.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.784903</td>\n",
       "      <td>0.678571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>80.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.972068</td>\n",
       "      <td>0.651786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>60.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.798838</td>\n",
       "      <td>0.651786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>100.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.784109</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>90.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.887830</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>90.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.800649</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>60.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.904156</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>60.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.925158</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>90.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.778993</td>\n",
       "      <td>0.633929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>60.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.865542</td>\n",
       "      <td>0.633929</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     maxwords  maxlen  embedding_dim      loss  accuracy\n",
       "337      60.0    30.0           80.0  0.784903  0.678571\n",
       "438      80.0    30.0           15.0  0.972068  0.651786\n",
       "331      60.0    30.0           50.0  0.798838  0.651786\n",
       "553     100.0    30.0           20.0  0.784109  0.642857\n",
       "494      90.0    30.0           10.0  0.887830  0.642857\n",
       "503      90.0    30.0           55.0  0.800649  0.642857\n",
       "313      60.0    25.0           55.0  0.904156  0.642857\n",
       "319      60.0    25.0           85.0  0.925158  0.642857\n",
       "495      90.0    30.0           15.0  0.778993  0.633929\n",
       "312      60.0    25.0           50.0  0.865542  0.633929"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.sort_values(by=['accuracy'], ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8416c75f",
   "metadata": {},
   "source": [
    "## 2. Dense 층 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5936c013",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 5/5 [1:35:16<00:00, 1143.30s/it]\n"
     ]
    }
   ],
   "source": [
    "bestmodel = None\n",
    "bestacc = 0\n",
    "bestmxwords = None\n",
    "bestmxlen = None\n",
    "bestembdim = None\n",
    "bestunit = None\n",
    "result_df = pd.DataFrame(columns=['maxwords', 'maxlen', 'embedding_dim', 'unit', 'loss', 'accuracy'])\n",
    "\n",
    "for mxwords in tqdm(range(20, 60+1, 10)):\n",
    "    for mxlen in [10, 15, 20, 25, 30]:\n",
    "        for embdim in range(10, 100+1, 5):\n",
    "            for unit in [16, 32, 48, 64]:\n",
    "                model = train_to_evaluate(X1, y, 'embedding1b_category.h5', mxwords, mxlen, embdim, unit)\n",
    "                result_df.loc[len(result_df)] = [mxwords, mxlen, embdim, unit, model[2], model[3]]\n",
    "                if bestacc < model[3]:\n",
    "                    bestmodel = model\n",
    "                    bestacc = model[3]\n",
    "                    bestmxwords = mxwords\n",
    "                    bestmxlen = mxlen\n",
    "                    bestembdim = embdim\n",
    "                    bestunit = unit\n",
    "                \n",
    "bestmodel[0].save('data/embedding1b_category.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b02842e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6696, loss: 0.9026\n",
      "--bestmxwords: 40, --bestmxlen: 20, --bestembdim: 50, --bestunit: 64\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy: {bestmodel[3]:.4f}, loss: {bestmodel[2]:.4f}')\n",
    "print(f'--bestmxwords: {bestmxwords}, --bestmxlen: {bestmxlen}, --bestembdim: {bestembdim}, --bestunit: {bestunit}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bd7a97f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>maxwords</th>\n",
       "      <th>maxlen</th>\n",
       "      <th>embedding_dim</th>\n",
       "      <th>unit</th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1024</th>\n",
       "      <td>40.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.815479</td>\n",
       "      <td>0.616071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1013</th>\n",
       "      <td>40.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.833425</td>\n",
       "      <td>0.598214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1061</th>\n",
       "      <td>40.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.854336</td>\n",
       "      <td>0.589286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007</th>\n",
       "      <td>40.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.860727</td>\n",
       "      <td>0.660714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950</th>\n",
       "      <td>40.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.869630</td>\n",
       "      <td>0.633929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1040</th>\n",
       "      <td>40.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.870210</td>\n",
       "      <td>0.589286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1075</th>\n",
       "      <td>40.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.873789</td>\n",
       "      <td>0.607143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018</th>\n",
       "      <td>40.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.894071</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011</th>\n",
       "      <td>40.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.895694</td>\n",
       "      <td>0.598214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1051</th>\n",
       "      <td>40.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.897124</td>\n",
       "      <td>0.589286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      maxwords  maxlen  embedding_dim  unit      loss  accuracy\n",
       "1024      40.0    25.0           55.0  16.0  0.815479  0.616071\n",
       "1013      40.0    25.0           40.0  32.0  0.833425  0.598214\n",
       "1061      40.0    25.0          100.0  32.0  0.854336  0.589286\n",
       "1007      40.0    25.0           30.0  64.0  0.860727  0.660714\n",
       "950       40.0    20.0           55.0  48.0  0.869630  0.633929\n",
       "1040      40.0    25.0           75.0  16.0  0.870210  0.589286\n",
       "1075      40.0    30.0           20.0  64.0  0.873789  0.607143\n",
       "1018      40.0    25.0           45.0  48.0  0.894071  0.642857\n",
       "1011      40.0    25.0           35.0  64.0  0.895694  0.598214\n",
       "1051      40.0    25.0           85.0  64.0  0.897124  0.589286"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.sort_values(by=['loss']).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3854df38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>maxwords</th>\n",
       "      <th>maxlen</th>\n",
       "      <th>embedding_dim</th>\n",
       "      <th>unit</th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>947</th>\n",
       "      <td>40.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.902617</td>\n",
       "      <td>0.669643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946</th>\n",
       "      <td>40.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.928112</td>\n",
       "      <td>0.660714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007</th>\n",
       "      <td>40.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.860727</td>\n",
       "      <td>0.660714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769</th>\n",
       "      <td>40.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.626126</td>\n",
       "      <td>0.651786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812</th>\n",
       "      <td>40.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.471952</td>\n",
       "      <td>0.651786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1829</th>\n",
       "      <td>60.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.002640</td>\n",
       "      <td>0.651786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>40.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.943214</td>\n",
       "      <td>0.651786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785</th>\n",
       "      <td>40.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.638763</td>\n",
       "      <td>0.651786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>936</th>\n",
       "      <td>40.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.101996</td>\n",
       "      <td>0.651786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1305</th>\n",
       "      <td>50.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.157982</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      maxwords  maxlen  embedding_dim  unit      loss  accuracy\n",
       "947       40.0    20.0           50.0  64.0  0.902617  0.669643\n",
       "946       40.0    20.0           50.0  48.0  0.928112  0.660714\n",
       "1007      40.0    25.0           30.0  64.0  0.860727  0.660714\n",
       "769       40.0    10.0           20.0  32.0  1.626126  0.651786\n",
       "812       40.0    10.0           75.0  16.0  1.471952  0.651786\n",
       "1829      60.0    30.0           15.0  32.0  1.002640  0.651786\n",
       "1001      40.0    25.0           25.0  32.0  0.943214  0.651786\n",
       "785       40.0    10.0           40.0  32.0  1.638763  0.651786\n",
       "936       40.0    20.0           40.0  16.0  1.101996  0.651786\n",
       "1305      50.0    20.0           25.0  32.0  1.157982  0.642857"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.sort_values(by=['accuracy'], ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14632991",
   "metadata": {},
   "source": [
    "## 특문 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6990a464",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 5/5 [1:37:59<00:00, 1175.89s/it]\n"
     ]
    }
   ],
   "source": [
    "bestmodel = None\n",
    "bestacc = 0\n",
    "bestmxwords = None\n",
    "bestmxlen = None\n",
    "bestembdim = None\n",
    "bestunit = None\n",
    "result_df = pd.DataFrame(columns=['maxwords', 'maxlen', 'embedding_dim', 'unit', 'loss', 'accuracy'])\n",
    "\n",
    "for mxwords in tqdm(range(20, 60+1, 10)):\n",
    "    for mxlen in [10, 15, 20, 25, 30]:\n",
    "        for embdim in range(10, 100+1, 5):\n",
    "            for unit in [16, 32, 48, 64]:\n",
    "                model = train_to_evaluate(X1a, y, 'embedding1c_category.h5', mxwords, mxlen, embdim, unit)\n",
    "                result_df.loc[len(result_df)] = [mxwords, mxlen, embdim, unit, model[2], model[3]]\n",
    "                if bestacc < model[3]:\n",
    "                    bestmodel = model\n",
    "                    bestacc = model[3]\n",
    "                    bestmxwords = mxwords\n",
    "                    bestmxlen = mxlen\n",
    "                    bestembdim = embdim\n",
    "                    bestunit = unit\n",
    "                \n",
    "bestmodel[0].save('data/embedding1c_category.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4d46a47c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7054, loss: 0.9835\n",
      "--bestmxwords: 60, --bestmxlen: 25, --bestembdim: 25, --bestunit: 48\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy: {bestmodel[3]:.4f}, loss: {bestmodel[2]:.4f}')\n",
    "print(f'--bestmxwords: {bestmxwords}, --bestmxlen: {bestmxlen}, --bestembdim: {bestembdim}, --bestunit: {bestunit}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2f5e34bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>maxwords</th>\n",
       "      <th>maxlen</th>\n",
       "      <th>embedding_dim</th>\n",
       "      <th>unit</th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1846</th>\n",
       "      <td>60.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.927900</td>\n",
       "      <td>0.633929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1848</th>\n",
       "      <td>60.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.947456</td>\n",
       "      <td>0.598214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1854</th>\n",
       "      <td>60.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.947719</td>\n",
       "      <td>0.633929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1862</th>\n",
       "      <td>60.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.953246</td>\n",
       "      <td>0.598214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1844</th>\n",
       "      <td>60.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.962221</td>\n",
       "      <td>0.616071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1887</th>\n",
       "      <td>60.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.963433</td>\n",
       "      <td>0.616071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1768</th>\n",
       "      <td>60.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.964076</td>\n",
       "      <td>0.598214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1137</th>\n",
       "      <td>40.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.965037</td>\n",
       "      <td>0.491071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1488</th>\n",
       "      <td>50.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.967874</td>\n",
       "      <td>0.553571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1850</th>\n",
       "      <td>60.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.974204</td>\n",
       "      <td>0.607143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      maxwords  maxlen  embedding_dim  unit      loss  accuracy\n",
       "1846      60.0    30.0           35.0  48.0  0.927900  0.633929\n",
       "1848      60.0    30.0           40.0  16.0  0.947456  0.598214\n",
       "1854      60.0    30.0           45.0  48.0  0.947719  0.633929\n",
       "1862      60.0    30.0           55.0  48.0  0.953246  0.598214\n",
       "1844      60.0    30.0           35.0  16.0  0.962221  0.616071\n",
       "1887      60.0    30.0           85.0  64.0  0.963433  0.616071\n",
       "1768      60.0    25.0           35.0  16.0  0.964076  0.598214\n",
       "1137      40.0    30.0          100.0  32.0  0.965037  0.491071\n",
       "1488      50.0    30.0           65.0  16.0  0.967874  0.553571\n",
       "1850      60.0    30.0           40.0  48.0  0.974204  0.607143"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.sort_values(by=['loss']).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e2798474",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>maxwords</th>\n",
       "      <th>maxlen</th>\n",
       "      <th>embedding_dim</th>\n",
       "      <th>unit</th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1762</th>\n",
       "      <td>60.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.983517</td>\n",
       "      <td>0.705357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1830</th>\n",
       "      <td>60.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1.106802</td>\n",
       "      <td>0.669643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1812</th>\n",
       "      <td>60.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.014190</td>\n",
       "      <td>0.651786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1836</th>\n",
       "      <td>60.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.016309</td>\n",
       "      <td>0.651786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>30.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.568066</td>\n",
       "      <td>0.651786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>30.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.573885</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>30.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1.374246</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1752</th>\n",
       "      <td>60.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.196743</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>30.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.521430</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1801</th>\n",
       "      <td>60.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.053362</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      maxwords  maxlen  embedding_dim  unit      loss  accuracy\n",
       "1762      60.0    25.0           25.0  48.0  0.983517  0.705357\n",
       "1830      60.0    30.0           15.0  48.0  1.106802  0.669643\n",
       "1812      60.0    25.0           90.0  16.0  1.014190  0.651786\n",
       "1836      60.0    30.0           25.0  16.0  1.016309  0.651786\n",
       "396       30.0    10.0           30.0  16.0  1.568066  0.651786\n",
       "421       30.0    10.0           60.0  32.0  1.573885  0.642857\n",
       "427       30.0    10.0           65.0  64.0  1.374246  0.642857\n",
       "1752      60.0    25.0           15.0  16.0  1.196743  0.642857\n",
       "445       30.0    10.0           90.0  32.0  1.521430  0.642857\n",
       "1801      60.0    25.0           75.0  32.0  1.053362  0.642857"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.sort_values(by=['accuracy'], ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cbd0812",
   "metadata": {},
   "source": [
    "# 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "60f1fe18",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Accuracy: 0.6786, loss: 0.7849\n",
    "--bestmxwords: 60, --bestmxlen: 30, --bestembdim: 80\n",
    "'''\n",
    "max_words = 60\n",
    "maxlen = 30\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(X1a)\n",
    "X_seq = tokenizer.texts_to_sequences(X1a)\n",
    "X_pad = pad_sequences(X_seq, maxlen=maxlen)\n",
    "y = np.asarray(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pad, y, test_size=0.2, random_state=0)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c0a9d046",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('data/embedding1a_category.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1c668c5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0031 - accuracy: 0.5071\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.003082275390625, 0.5071428418159485]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4af801dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_orig, X_test_orig, y_train_orig, y_test_orig = train_test_split(df['best'], df['star'], test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "095f6dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "356482eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "432    9.50\n",
       "266    9.57\n",
       "251    9.72\n",
       "103    8.81\n",
       "674    9.69\n",
       "215    8.90\n",
       "312    9.44\n",
       "608    9.70\n",
       "532    8.72\n",
       "406    8.38\n",
       "162    9.54\n",
       "496    9.75\n",
       "279    9.53\n",
       "478    8.80\n",
       "200    9.78\n",
       "568    7.02\n",
       "267    8.96\n",
       "477    9.56\n",
       "242    9.76\n",
       "417    9.75\n",
       "466    9.22\n",
       "229    9.47\n",
       "294    9.41\n",
       "245    9.76\n",
       "634    8.63\n",
       "261    9.66\n",
       "37     6.28\n",
       "666    9.79\n",
       "181    9.73\n",
       "272    9.75\n",
       "465    7.22\n",
       "210    9.65\n",
       "230    9.74\n",
       "310    9.52\n",
       "644    9.78\n",
       "Name: star, dtype: float64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_orig[y_test_orig < 9.8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a2b0be31",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_orig_copy = y_test_orig.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "de3f71de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3      9.50\n",
       "6      9.57\n",
       "8      9.72\n",
       "9      8.81\n",
       "10     9.69\n",
       "12     8.90\n",
       "13     9.44\n",
       "21     9.70\n",
       "27     8.72\n",
       "32     8.38\n",
       "34     9.54\n",
       "36     9.75\n",
       "37     9.53\n",
       "42     8.80\n",
       "44     9.78\n",
       "47     7.02\n",
       "53     8.96\n",
       "56     9.56\n",
       "61     9.76\n",
       "67     9.75\n",
       "73     9.22\n",
       "78     9.47\n",
       "79     9.41\n",
       "81     9.76\n",
       "84     8.63\n",
       "93     9.66\n",
       "94     6.28\n",
       "106    9.79\n",
       "115    9.73\n",
       "119    9.75\n",
       "129    7.22\n",
       "130    9.65\n",
       "133    9.74\n",
       "135    9.52\n",
       "136    9.78\n",
       "Name: star, dtype: float64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_orig_copy[y_test_orig_copy < 9.8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "654f41e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'언제나 오덕으로 나오는 캐릭터는 안경에,주근깨에,사회생활 부적응자에 다키마쿠라껴안고다니면서 하악거리는건 똑같네.애니,만화 좋아하는게 아이돌 좋아하는거랑뭐 크게 다른줄아시나요...웹툰보면 아이돌좋아하는 애는 예쁘고 친구들도 많은데애니좋아하는 사람만 이렇게 나오는거 이제지친다...\\n나는 별론데.. .덕후가 저렇게 표현되는건 좀.. .\\n저도 오덕으로써 한마디 하겠습니다.일단 덕후들 다 쿠션가지고 하앜 거리지 않아요그리고 일본어를 조금씩은 할 줄 알겠지만 아침부터 히사시부리 라면서 이목끌지는 않아요...애니를 본다고 차별하는게 너무 싫어서 이 웹툰을 보고 눈이 찌푸려 졌어요 ㅜㅜㅜ그래도 아직 1화고 더 성장하길 것 같아요.아 그리고 이기자 그린 잘봤습니다!!\\n요리고 이어서 만화고?\\n여기서 메갈이 왜나와 ,,? ㅋㅋㅋㅋ 너무 예민하게 반응하네 ; 심하다\\n믿기지 않으시겠지만 이분이 기자 이야기 쓰신분입니다..\\n나도 덕후디만 저런식으로 표현되는거 싫어 이런것들 때문에 그냥 애니 보는거만 좋아하는 사람들한태도 이상한 인식 박혀서 맨날 욕먹고 팩트폭행해줘도 맨날 덕후는 믿고 거른다면서 무심가고 나보다 못한놈들이\\n덕후 이미지를 안여돼+~했다능+캐릭터 베개 들고 하악 거리는 사람으로 박아놓는 것 같아서 별로다.. 선입견만 모아둔 완전체 극혐.\\n공감 고민툰 급은 아니지만 덕후에 대한 편견이 심하여 조치가 필요함.\\n덕후에 대한 스테레오타입들을 일부로 싸그리 모아서 외적으로 나타낸 캐릭터니까 당연히 저렇게 그려지죠... 아직 1화고 주인공의 배경도 상세히 나오지 않은 마당에 벌써부터 단정하는건 섣부른 판단이 아닐까요? 작가로써는 이 사람이 우리가 생각하는 오타쿠다 라고 표현하고싶었는데 난데없이 엄청 예쁘고 섹시한 여주가 나오면 독자들이 내가 원하는 주인공의 모습을 오해하는건 아닐까, 하고 생각해서 이렇게 그렸을 수도 있어요.그리고 댓글에서 서로의 의견 표현은 자유로울 수 있으나 사적 감정이 개입되면 비방과 싸움이 일어날 수 있으니 다들 조심하시는게 좋을 것 같습니다.\\n김8작가님이라면 어떤 고구마도 두렵지 않다!최소 몇컷 길게잡아야 두편만에 사이다 까시고 스뿌라잇 샤워 하실분이라...\\n무심코 내리다가온사람 손\\n본인들이 저러나 왜케 민감함 ㅋㅋㅋㅋㅋ 작가가 덕후는 죄다 씹덕이랬나ㅋㅋㅋㅋㅋㅋㅋ\\n오타쿠라고 했을때 반응일반인:뭐래 ㅋㅋㅋ ㅁㅊ씹뜨억:오타쿠가 무슨 뜻인지는 알고 쓰는거니?오타쿠는 일본에서시작되어 어느 어느 분야에 과하게열중하는 것이나 이런 사람을 말학고과하다 싶을 정도지나치게 많이과도하다고 해야 할 정도로한 곳에 열중인 것을 말하거든. 다시는 오타쿠를 무시하지마라\\n이게 그 첫 인상이 구려서 별점 테러 받았다 용으로 승천한 갓 웹툰인가?'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_orig.iloc[129]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bde4d48c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7.22, array([0.9599828], dtype=float32))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_orig.iloc[129], pred[129]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "389aa189",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'솔직히 내용 다 까먹어서 정주행하려햇는데 유료화돼서 못본사람 손\\n휴재의하늘\\n아니 무슨 11개월만에 왔는데 죄송하단 말한번없어.\\n맨날 휴재하더니 이제 휴재하면 안볼래요 그냥.\\n시즌3을 기억못하시는분들을 위해 써요심연의 하늘은 시즌3때 하늘로 생각했던 사다리를 올라오고 표지판을 보게되죠 도시는 소용돌이같이 갑자기 쓸어가고 어느날은 구멍도 한번에 파이게 되죠 그러고 둘은 떨어지게 되고 여자아이는 헬리콥터도타다가 하늘을 계속 찾게 됩니다. 그러다가 결국 둘은 만나고 휴재되었죠.작가님 휴재기간이 길면 내용파악이 안되서 힘들어요\\nㅋㅋㅋ 누가 돈이 없어서 유료화가 짜증나는거냐?? ㅋㅋㅋ 뭔 200원가지고 있는척들이야 ㅋㅋㅋ 돈이 없어서 짜증나는게 아니라 작자 하는 꼬라지가 짜증나는거다\\n여기 사람들이 지금 결제하는 돈이 아깝다고 글쓰는거 아니잖아난독증 있는 사람들 몇명 있는거 같네처음 스마트툰 연재때부터 보던 사람들은 알겠지만원래 이 웹툰 원래 휴재 오지게 땡기던 웹툰임근데 이번에는 그 기간도 길었을 뿐더러작가 매일 술마시고 노는 영상이 페북에 올라다녔다는데자기 작품 완결도 안낸상태에서 장기간 휴재해놓고 스토어에 올려버리면 아무리 애정갖고 보던 독자들도 좀 어이없지않겠냐?\\n차원만화 보고있었는데 나오니까 하나더 생겻다\\n마지막에 중국인이 둘이 만난거보고 미사일 떨궜음\\n왜 유로화함 기억하지도 멋하는데;\\n술먹을돈 떨어졌냐? 어차피 돈좀벌리면 또 휴재할꺼 그냥평생하지마라 그 따위로 일할거면\\n앞의 내용이 전혀 기억나지 않는다둘다 인간이긴 하냐?\\n도대체 연재만 몇번을 봐야하는지 이렇게 30화정도 내고 또 끊길듯\\n시즌3마지막 기억이안나ㅠㅠ 설명충등판좀..\\n처음에 작가의 말 . 이었답니다. 댓글 보고 고친거래요. 아무려면 그냥 베댓이 됐겠어요?? 작가가 댓글 보고 고치는 바람에 베댓되신분만 갈수록 싫어요가 많아지는 게 보여서 한마디 남깁니다.원래는 . 이었다는 댓글이 베댓만 올라갔어도 베댓된 분이 이처럼 욕을 먹진 않을텐데 말이죠.뒤늦게 본 사람들이 단지 작가의 말 수정된 것만 보고 베댓분 싫어요를 누를 게 아니라 괜히 베댓이 된 게 아니니까 원래는 없었나하는 생각을 하던지 아니면 전체댓글이라도 좀 어느정도 보면 금방 알텐데요.저도 베댓분 덕분에 원래는 . 이었다는 사실을 알 수 있었네요.그냥 . 이었다가 고친 걸 보니 작가가 좀 얄밉게 느껴지네요.거의 1년이나 휴재하고 돌아왔으면 기다려준 독자들을 생각했다면 애초부터 작가의 말에 한마디 뭔 말이라도 있어야 했던 게 당연한 게 아닌가하는 생각이 드네요.'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_orig.iloc[47]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ce6afb5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7.02, array([0.91515267], dtype=float32))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_orig.iloc[47], pred[47]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e5279c23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'밑그림 남아있는건 좀 너무하지 않냐 한 컷도 아니고 대부분의 컷이 그럼\\n네웹 어디 학원에서 넣어준다는 소문 있던데 진짜인가 보네...\\n털선을 자기 아이덴티티로 밀고 갈 생각인진 모르겠지만 이건 그림을 잘 그리고 못 그리기 이전에 완성도와 성의의 문제임. 연습장에 그리다 만 그림같은 퀄리티를 네이버에서 정식연재한다고?\\n선 정리 조금만 해주면 진짜 좋을것 같은데 그점 빼고는 다 좋은거 같네요\\n내용이랑 그림체는 많이안나쁜데..잡선이 너무많이보이네요 파일잘못 올리셨낭..?\\n작가님 한텐 좀 죄송하긴 하다만 솔직히 네이버 요즘 일 안하는거같음 베도만 가 봐도 그림이쁘고 깔끔하고 스토리 탄탄한거 좀만 둘러봐도 나오는데。。。 이건 좀 아닌것같음\\n작가가털선쓰는건첨보네\\n이런 그림은 개성이 아니라 못그린거야 개성은 다른거지\\n진짜 죄송한데..이건 뭐 느낌이 있는 그림도 아닌거 같구 털선 너무 보기가 싫음 털선임..가끔 털선이여도 예쁜 털선이 있는데 이건 걍 털선 그 자체.. 털선때문에 내용에 집중을 못하겠음..\\n뭐야.. 베도에 이거보다 퀄 좋고 스토리 구성 좋은 작품 많은데.. 왜 베도도 아니고 이런 퀄을 그리는 작가들을 데리고 오는거지?\\n털선 이어붙이기가 좀 심함 그림 그리는 사람이라면 털선은 모두가 싫어하는데\\n그림을 학원에서 배우던 독학을 하던 먼저 해야하는건 선 연습이에요.그 기초도 안되어있으니 사람들의 시선이 불편하죠..\\n밑밑밑댓 미술 안 배워본듯. 선 좀 지저분한 걸 떠나서 구도 인체비율 투시 틀린 거 많음 ㅋㅋ 당장 배경만 해도 투시 다 틀렸는데? 앵글에 맞지 않게 사람 넣은 컷도 보이고. 인체비율은 작가 개성이라고 봐도 문제될 거 없지만 배경 투시는 진짜 수학책 입체도형 자료 급으로 위아래 선이 평행한데 뭔 투시가 맞아 ㅋㅋ 소실점이 어딨는지도 못찾겠더라 난.. 그리고 물타기물타기 하는데 오히려 지금 작화 감싸는 게 더 물타기같다고 생각됨. 개성있고 보기 좋다고? 아니 못그리는 걸 못그린다고 말하는게 어떻게 물타기야 ㅋㅋㅋ 보기 싫으면 보지 말라고?? 그럼 아무나 네웹에서 욕먹으면서 연재하지,, 직업이잖아 이걸로 벌어먹고 살 텐데. 베도만 봐도 훨씬 퀄 높은 작품들 많은데 굳이 이런 작품들 데려와서 돈 맥여주는게 정상적인지 모르겠다. 이렇게 많은 사람들이 욕 하는데엔 이유가 있는거야\\n에이 실력 늘겠죠~~ 지켜봅시다 <-이거 딱 일본아이돌 마인드아님? \\n아랫분 당연히 중요하죠; 물론 비난이 좋은건 아니지만 이거 취미로 하시는거나 베도 도전만화 이런거면 괜찮은데 이분들은 돈 받고 하시는거잖아요. 이렇게 퀄리티 없게 그려가면서 돈까지 받아간다? 그게 옳지 못하다고 생각해서 그러는거잖아요. 취미로 하면 문제 없지만 이걸 직업으로 삼으니까 그렇죠.'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_orig.iloc[94]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "911f0ada",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6.28, array([0.15195438], dtype=float32))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_orig.iloc[94], pred[94]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb192a4",
   "metadata": {},
   "source": [
    "이 또한 결과는 별로인 것 같다.  \n",
    "1화 베댓으로 평점을 예측한다는 가정이 틀린 걸까"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38908415",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python Multi",
   "language": "python",
   "name": "multi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
